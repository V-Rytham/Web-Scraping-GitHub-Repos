{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b592b4",
   "metadata": {},
   "source": [
    "# Web Scrapping Project - Top GitHub Repositories in Selected Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d3a0f",
   "metadata": {},
   "source": [
    "![Web_Scrapping using Python and Beautiful Soup](https://imgur.com/a/Ff2VVlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17640454",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "### About Web Scrapping \n",
    "\n",
    "        `Web scraping` is a data extraction technique used to gather information from websites programmatically. The provided Python code showcases a web scraping application focused on GitHub topics and repositories.\n",
    "    \n",
    "    \n",
    "### Introduction about Github\n",
    "\n",
    "        GitHub is a web-based platform that provides version control and collaboration tools for software development. It facilitates code sharing, collaboration, and project management through features like repositories, pull requests, and issue tracking. Developers use GitHub to manage and track changes in their code, making it a central hub for open-source projects and collaborative coding effort.\n",
    "\n",
    "\n",
    "        This project utilizes libraries such as requests for fetching HTML, BeautifulSoup for parsing, and Pandas for data manipulation. The script extracts and organizes GitHub topic and repository details, saving the information into structured CSV files. This approach is valuable for automating data collection from websites for various purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b7e43",
   "metadata": {},
   "source": [
    "Here are the steps we would follow:\n",
    "- We're going to scrape https://github.com/topics\n",
    "- We'll get a list of topics. For each topic,we'll get topic title, topic page URL, and topic description \n",
    "- For each topic, we'll get the top 10 repositories in the topic from the topic page \n",
    "- For each repository, we'll grab the repo name, username, stars, repo URL\n",
    "- For each topic we'll create a CSV file in the following format \n",
    "```\n",
    "    Repo name, Username, Stars, Repo URL \n",
    "     mrdoob,threejs,96900,https://github.com/mrdoob/three.js\t\n",
    "    pmndrs,react-three-fiber,250000,https://github.com/pmndrs/react-three-fiber\t\n",
    "```\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4383a1",
   "metadata": {},
   "source": [
    "### Packages Used:\n",
    "    \n",
    "    1. Requests — For downloading the HTML code from the IMDB URL\n",
    "    2. BeautifulSoup4 — For parsing and extracting data from the HTML string\n",
    "    3. Pandas — to gather my data into a dataframe for further processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f022b4f",
   "metadata": {},
   "source": [
    "## Scrape the list of topics from Github\n",
    "\n",
    "Explain how you do it \n",
    "\n",
    "- use requests to download the page\n",
    "- user BS4 to parse and extract information \n",
    "- convert to a Pandas dataframe \n",
    "\n",
    "Let's write a function to download the page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe74be",
   "metadata": {},
   "source": [
    "### Lets begin:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d505a",
   "metadata": {},
   "source": [
    "### Download the webpage using requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb114396",
   "metadata": {},
   "source": [
    "#### What is requests\n",
    "`Requests` is a Python HTTP library that allows us to send `HTTP requests` to servers of websites, instead of using browsers to communicate the web.\n",
    "\n",
    "    We use pip, a package-management system, to install and manage softwares. Since the platform we selected is Binder, we would have to type a line of code !pip install to install requests. You will see lots codes of !pip when installing other packages.\n",
    "\n",
    "    When we attempt to use some prewritten functions from a certain library, we would use the import statement. e.g. When we would have to type import requests after installation, we are able to use any function from requests library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e4971efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def get_page(url):\n",
    "    # Download the page\n",
    "    response = requests.get(url)\n",
    "    #Check successful response \n",
    "    #parse using beautiful soup is response is successful \n",
    "    if 200 <= response.status_code <= 299:\n",
    "        page_contents = response.text\n",
    "        doc = BeautifulSoup(page_contents, 'html.parser')\n",
    "        return doc\n",
    "    else:\n",
    "        raise Exception(f\"Unable to fetch the given page {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb220ce",
   "metadata": {},
   "source": [
    "A function that retrieves the HTML content of a given URL using the requests library. It checks for a successful response and returns a BeautifulSoup object for further parsing.\n",
    "\n",
    "The successful response is checked using .status_code function provided by the requests library. If the send request is successful then the value of status_code should lie anywhere between 200 and 299. \n",
    "\n",
    "A beautiful soup object is created which we will use throughout the project to parse the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "60efbca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=get_page(\"https://github.com/topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4d0b8736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb2af85",
   "metadata": {},
   "source": [
    "Let's create some helper functions to parse information "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b174b4",
   "metadata": {},
   "source": [
    "#### What is HTML?\n",
    "\n",
    "Before we dive into how to inspect HTML, we should know the basic knowledge about HTML.\n",
    "\n",
    "    The HyperText Markup Language, or HTML is the standard markup language for documents designed to be displayed in a web browser. It can be assisted by technologies such as Cascading Style Sheets and scripting languages such as JavaScript.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc1933",
   "metadata": {},
   "source": [
    "#### An HTML tag comprises of three parts:\n",
    "\n",
    "    1 Name: (html, head, body, div, etc.) Indicates what the tag represents and how a browser should interpret the information inside it.\n",
    "    2. Attributes: (href, target, class, id, etc.) Properties of tag used by the browser to customize how a tag is displayed and decide what happens on user interactions.\n",
    "    3. Children: A tag can contain some text or other tags or both between the opening and closing segments, e.g., <div>Some content</div>.\n",
    "#### Common tags and attributes\n",
    "\n",
    "##### Tags in HTML\n",
    "\n",
    "    There are around 100 types of HTML tags but on a day to day basis, around 15 to 20 of them are the most common use, such as <div> tag, <p> tag, <section> tag, <img> tag, <a> tags.\n",
    "\n",
    "    Of many tags, I wanted to highlight <a> tag, which can contain attributes such as href (hyperlink reference), because <a> tag allows users to click and they would be directed to another site. That's why the name of <a> tag is anchor.\n",
    "\n",
    "##### Attributes\n",
    "    Each tag supports several attributes. Following are some common attributes used to modify the behavior of tags\n",
    "\n",
    "- id\n",
    "- style\n",
    "- class\n",
    "- href (used with <a>)\n",
    "- src (used with <img>tag)\n",
    "\n",
    "    What we can do with **a BeautifulSoup object** is to get **a specifc types of a tag in HTML** by calling the name of a tag, as shown in code cell below.\n",
    "\n",
    "Here, we use the find() function of BeautifulSoup to find the first <title> tag in the HTML document and display its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7979f5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Topics on GitHub · GitHub</title>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=doc.find('title')\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac55e17",
   "metadata": {},
   "source": [
    "### GitHub Topics \n",
    "                                                         \n",
    "    Now we will use 'BeautifulSoup' to extract The names, URLs of the top 30 topics \n",
    "                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fab89ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas --quiet --upgrade  \n",
    "import pandas as pd\n",
    "topics_titles,topic_descs,topic_urls=parse_page(doc)\n",
    "topics_dict={\n",
    "        'title': topic_titles,\n",
    "        'description': topic_descs,\n",
    "        'url': topic_urls\n",
    "}\n",
    "topics_df = pd.DataFrame(topics_dict)  #Here we convert the dictionary into a Pandas DataFrame\n",
    "topics_df.to_csv('topics.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c641f72",
   "metadata": {},
   "source": [
    "`parse_page(doc)`: This function extracts information about GitHub topics from the parsed HTML document. It collects data such as `topic titles`, `descriptions`, and constructs `topic URLs`and returns a dictionary of lists containing the above data.The other chunck of code saves the data in a dictionary and then a dataframe is created where the dictionary is stored in dataframe form.\n",
    "\n",
    "This df is at the end saved as a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c277d1f",
   "metadata": {},
   "source": [
    "##### What is Pandas?\n",
    "\n",
    "    Pandas is a software library written for the Python programming language for data manipulation and analysis.\n",
    "    In particular, it offers data structures and operations for manipulating numerical tables and time series.\n",
    "\n",
    "##### What is a DataFrame?\n",
    "\n",
    "    A Pandas DataFrame is a 2 dimensional data structure, like a 2 dimensional array, or a table with rows and columns.\n",
    "    DataFrame makes it easier for us to work with tablular data and analse it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5088fc",
   "metadata": {},
   "source": [
    "Now, Let us check the length of the Dataframe that we have created which contains the `topic name` `description` and `url`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5afc27b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7940fd",
   "metadata": {},
   "source": [
    "We can see that the DataFrame consists of 30 items, that is equal to the number of topics that we have on the page `Github topics`.\n",
    "\n",
    "Therefore, we can be sure that we have extracted the complete information that we had intended to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecda740",
   "metadata": {},
   "source": [
    "Now the next step is to scrape each website obtained in the URL and parse the information of top 10 repositories in each topic and ultimately store it in a `pandas df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc7dd9",
   "metadata": {},
   "source": [
    "![_](https://imgur.com/a/Ff2VVlp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1749b7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>3D refers to the use of three-dimensional grap...</td>\n",
       "      <td>https://github.com/topic/3D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax is a technique for creating interactive w...</td>\n",
       "      <td>https://github.com/topic/Ajax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>Algorithms are self-contained sequences that c...</td>\n",
       "      <td>https://github.com/topic/Algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amp</td>\n",
       "      <td>Amp is a non-blocking concurrency library for ...</td>\n",
       "      <td>https://github.com/topic/Amp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Android</td>\n",
       "      <td>Android is an operating system built by Google...</td>\n",
       "      <td>https://github.com/topic/Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Angular</td>\n",
       "      <td>Angular is an open source web application plat...</td>\n",
       "      <td>https://github.com/topic/Angular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ansible</td>\n",
       "      <td>Ansible is a simple and powerful automation en...</td>\n",
       "      <td>https://github.com/topic/Ansible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>API</td>\n",
       "      <td>An API (Application Programming Interface) is ...</td>\n",
       "      <td>https://github.com/topic/API</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arduino</td>\n",
       "      <td>Arduino is an open source platform for buildin...</td>\n",
       "      <td>https://github.com/topic/Arduino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASP.NET</td>\n",
       "      <td>ASP.NET is a web framework for building modern...</td>\n",
       "      <td>https://github.com/topic/ASP.NET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Atom</td>\n",
       "      <td>Atom is a open source text editor built with w...</td>\n",
       "      <td>https://github.com/topic/Atom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Awesome Lists</td>\n",
       "      <td>An awesome list is a list of awesome things cu...</td>\n",
       "      <td>https://github.com/topic/Awesome Lists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Amazon Web Services</td>\n",
       "      <td>Amazon Web Services provides on-demand cloud c...</td>\n",
       "      <td>https://github.com/topic/Amazon Web Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Azure</td>\n",
       "      <td>Azure is a cloud computing service created by ...</td>\n",
       "      <td>https://github.com/topic/Azure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Babel</td>\n",
       "      <td>Babel is a compiler for writing next generatio...</td>\n",
       "      <td>https://github.com/topic/Babel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bash</td>\n",
       "      <td>Bash is a shell and command language interpret...</td>\n",
       "      <td>https://github.com/topic/Bash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin is a cryptocurrency developed by Satos...</td>\n",
       "      <td>https://github.com/topic/Bitcoin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bootstrap</td>\n",
       "      <td>Bootstrap is an HTML, CSS, and JavaScript fram...</td>\n",
       "      <td>https://github.com/topic/Bootstrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bot</td>\n",
       "      <td>A bot is an application that runs automated ta...</td>\n",
       "      <td>https://github.com/topic/Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C</td>\n",
       "      <td>C is a general purpose programming language th...</td>\n",
       "      <td>https://github.com/topic/C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chrome</td>\n",
       "      <td>Chrome is a web browser from the tech company ...</td>\n",
       "      <td>https://github.com/topic/Chrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chrome extension</td>\n",
       "      <td>Chrome extensions enable users to customize th...</td>\n",
       "      <td>https://github.com/topic/Chrome extension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Command line interface</td>\n",
       "      <td>A CLI, or command-line interface, is a console...</td>\n",
       "      <td>https://github.com/topic/Command line interface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Clojure</td>\n",
       "      <td>Clojure is a dynamic, general-purpose programm...</td>\n",
       "      <td>https://github.com/topic/Clojure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Code quality</td>\n",
       "      <td>Automate your code review with style, quality,...</td>\n",
       "      <td>https://github.com/topic/Code quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Code review</td>\n",
       "      <td>Ensure your code meets quality standards and s...</td>\n",
       "      <td>https://github.com/topic/Code review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Compiler</td>\n",
       "      <td>Compilers are software that translate higher-l...</td>\n",
       "      <td>https://github.com/topic/Compiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Continuous integration</td>\n",
       "      <td>Automatically build and test your code as you ...</td>\n",
       "      <td>https://github.com/topic/Continuous integration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>The coronavirus disease 2019 (COVID-19) is an ...</td>\n",
       "      <td>https://github.com/topic/COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>C++</td>\n",
       "      <td>C++ is a general purpose and object-oriented p...</td>\n",
       "      <td>https://github.com/topic/C++</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                        description  \\\n",
       "0                       3D  3D refers to the use of three-dimensional grap...   \n",
       "1                     Ajax  Ajax is a technique for creating interactive w...   \n",
       "2                Algorithm  Algorithms are self-contained sequences that c...   \n",
       "3                      Amp  Amp is a non-blocking concurrency library for ...   \n",
       "4                  Android  Android is an operating system built by Google...   \n",
       "5                  Angular  Angular is an open source web application plat...   \n",
       "6                  Ansible  Ansible is a simple and powerful automation en...   \n",
       "7                      API  An API (Application Programming Interface) is ...   \n",
       "8                  Arduino  Arduino is an open source platform for buildin...   \n",
       "9                  ASP.NET  ASP.NET is a web framework for building modern...   \n",
       "10                    Atom  Atom is a open source text editor built with w...   \n",
       "11           Awesome Lists  An awesome list is a list of awesome things cu...   \n",
       "12     Amazon Web Services  Amazon Web Services provides on-demand cloud c...   \n",
       "13                   Azure  Azure is a cloud computing service created by ...   \n",
       "14                   Babel  Babel is a compiler for writing next generatio...   \n",
       "15                    Bash  Bash is a shell and command language interpret...   \n",
       "16                 Bitcoin  Bitcoin is a cryptocurrency developed by Satos...   \n",
       "17               Bootstrap  Bootstrap is an HTML, CSS, and JavaScript fram...   \n",
       "18                     Bot  A bot is an application that runs automated ta...   \n",
       "19                       C  C is a general purpose programming language th...   \n",
       "20                  Chrome  Chrome is a web browser from the tech company ...   \n",
       "21        Chrome extension  Chrome extensions enable users to customize th...   \n",
       "22  Command line interface  A CLI, or command-line interface, is a console...   \n",
       "23                 Clojure  Clojure is a dynamic, general-purpose programm...   \n",
       "24            Code quality  Automate your code review with style, quality,...   \n",
       "25             Code review  Ensure your code meets quality standards and s...   \n",
       "26                Compiler  Compilers are software that translate higher-l...   \n",
       "27  Continuous integration  Automatically build and test your code as you ...   \n",
       "28                COVID-19  The coronavirus disease 2019 (COVID-19) is an ...   \n",
       "29                     C++  C++ is a general purpose and object-oriented p...   \n",
       "\n",
       "                                                url  \n",
       "0                       https://github.com/topic/3D  \n",
       "1                     https://github.com/topic/Ajax  \n",
       "2                https://github.com/topic/Algorithm  \n",
       "3                      https://github.com/topic/Amp  \n",
       "4                  https://github.com/topic/Android  \n",
       "5                  https://github.com/topic/Angular  \n",
       "6                  https://github.com/topic/Ansible  \n",
       "7                      https://github.com/topic/API  \n",
       "8                  https://github.com/topic/Arduino  \n",
       "9                  https://github.com/topic/ASP.NET  \n",
       "10                    https://github.com/topic/Atom  \n",
       "11           https://github.com/topic/Awesome Lists  \n",
       "12     https://github.com/topic/Amazon Web Services  \n",
       "13                   https://github.com/topic/Azure  \n",
       "14                   https://github.com/topic/Babel  \n",
       "15                    https://github.com/topic/Bash  \n",
       "16                 https://github.com/topic/Bitcoin  \n",
       "17               https://github.com/topic/Bootstrap  \n",
       "18                     https://github.com/topic/Bot  \n",
       "19                       https://github.com/topic/C  \n",
       "20                  https://github.com/topic/Chrome  \n",
       "21        https://github.com/topic/Chrome extension  \n",
       "22  https://github.com/topic/Command line interface  \n",
       "23                 https://github.com/topic/Clojure  \n",
       "24            https://github.com/topic/Code quality  \n",
       "25             https://github.com/topic/Code review  \n",
       "26                https://github.com/topic/Compiler  \n",
       "27  https://github.com/topic/Continuous integration  \n",
       "28                https://github.com/topic/COVID-19  \n",
       "29                     https://github.com/topic/C++  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2547ce1f",
   "metadata": {},
   "source": [
    "#### Next Steps\n",
    "\n",
    "Now, we will go into each individual topic's page and extract the rest of the required information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8bd8fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_title=[];\n",
    "topic_descs=[];\n",
    "topic_url=[];\n",
    "topic_title_tags=doc.find_all('p',class_=\"f3 lh-condensed mb-0 mt-1 Link--primary\");\n",
    "for tag in topic_title_tags:\n",
    "        topic_title.append(tag.text);\n",
    "\n",
    "topic_desc_tags=doc.find_all('p',class_=\"f5 color-fg-muted mb-0 mt-1\")\n",
    "for tag in topic_desc_tags:\n",
    "        topic_descs.append(tag.text.strip());\n",
    "\n",
    "topic_link_tags = doc.find_all('a',class_=\"no-underline flex-1 d-flex flex-column\")\n",
    "base_url=\"https://github.com/topic/\"\n",
    "for tag in topic_title:\n",
    "    topic_url.append(base_url+tag);\n",
    "\n",
    "#read the above data to pandas df and convert it to csv\n",
    "topic_dict={\n",
    "    'title':topic_title,\n",
    "    'description':topic_descs,\n",
    "    'url':topic_url\n",
    "}\n",
    "topic_df=pd.DataFrame(topic_dict)\n",
    "topic_df.to_csv('topics.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f4c7db",
   "metadata": {},
   "source": [
    "Let's start with extracting all the information for the topic 3D, which is the first topic in our list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "958f3554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/topic/3D'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "36dfa862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_page = topic_urls[0]  #To get information from the 1st movie among Most Popular Movies\n",
    "response = requests.get(topic_page)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b497c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488791"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376eede",
   "metadata": {},
   "source": [
    "Now, we will use `BeautifulSoup` to extract the required info from the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99ac671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4249f6",
   "metadata": {},
   "source": [
    "##### Repository name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2b91367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_tags=doc2.find_all('h3',class_=\"f3 color-fg-muted text-normal lh-condensed\")\n",
    "repo_names = [tag.find_all('a')[1].text.strip() for tag in h3_tags[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d9d2d6",
   "metadata": {},
   "source": [
    "###### User name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d4a05caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_names = [tag.find_all('a')[0].text.strip() for tag in h3_tags[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6c59f",
   "metadata": {},
   "source": [
    "##### Number of stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ab68499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_tags = doc2.find_all('span', {'id': \"repo-stars-counter-star\"})\n",
    "stars_set = [int(float(tag.text[:-1]) * 1000) if tag.text[-1] == 'k' else int(tag.text) for tag in star_tags[:10]]           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb73445",
   "metadata": {},
   "source": [
    "##### Repo URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9f2f8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_URLS = [f\"https://github.com/topics{tag.find_all('a')[0]['href']}\" for tag in h3_tags[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c717235",
   "metadata": {},
   "source": [
    "Now we have all the required information for the topic 3D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5656ca8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the topic 3D, the dataframe is : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repo name</th>\n",
       "      <th>User name</th>\n",
       "      <th>Star count</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>three.js</td>\n",
       "      <td>mrdoob</td>\n",
       "      <td>97000</td>\n",
       "      <td>https://github.com/topics/mrdoob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>react-three-fiber</td>\n",
       "      <td>pmndrs</td>\n",
       "      <td>25000</td>\n",
       "      <td>https://github.com/topics/pmndrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>libgdx</td>\n",
       "      <td>libgdx</td>\n",
       "      <td>22400</td>\n",
       "      <td>https://github.com/topics/libgdx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Babylon.js</td>\n",
       "      <td>BabylonJS</td>\n",
       "      <td>21900</td>\n",
       "      <td>https://github.com/topics/BabylonJS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tinyrenderer</td>\n",
       "      <td>ssloy</td>\n",
       "      <td>18700</td>\n",
       "      <td>https://github.com/topics/ssloy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3d-game-shaders-for-beginners</td>\n",
       "      <td>lettier</td>\n",
       "      <td>16600</td>\n",
       "      <td>https://github.com/topics/lettier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FreeCAD</td>\n",
       "      <td>FreeCAD</td>\n",
       "      <td>16500</td>\n",
       "      <td>https://github.com/topics/FreeCAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aframe</td>\n",
       "      <td>aframevr</td>\n",
       "      <td>16000</td>\n",
       "      <td>https://github.com/topics/aframevr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cesium</td>\n",
       "      <td>CesiumGS</td>\n",
       "      <td>11400</td>\n",
       "      <td>https://github.com/topics/CesiumGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blender</td>\n",
       "      <td>blender</td>\n",
       "      <td>10700</td>\n",
       "      <td>https://github.com/topics/blender</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Repo name  User name  Star count  \\\n",
       "0                       three.js     mrdoob       97000   \n",
       "1              react-three-fiber     pmndrs       25000   \n",
       "2                         libgdx     libgdx       22400   \n",
       "3                     Babylon.js  BabylonJS       21900   \n",
       "4                   tinyrenderer      ssloy       18700   \n",
       "5  3d-game-shaders-for-beginners    lettier       16600   \n",
       "6                        FreeCAD    FreeCAD       16500   \n",
       "7                         aframe   aframevr       16000   \n",
       "8                         cesium   CesiumGS       11400   \n",
       "9                        blender    blender       10700   \n",
       "\n",
       "                                   URL  \n",
       "0     https://github.com/topics/mrdoob  \n",
       "1     https://github.com/topics/pmndrs  \n",
       "2     https://github.com/topics/libgdx  \n",
       "3  https://github.com/topics/BabylonJS  \n",
       "4      https://github.com/topics/ssloy  \n",
       "5    https://github.com/topics/lettier  \n",
       "6    https://github.com/topics/FreeCAD  \n",
       "7   https://github.com/topics/aframevr  \n",
       "8   https://github.com/topics/CesiumGS  \n",
       "9    https://github.com/topics/blender  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"For the topic 3D, the dataframe is : \")\n",
    "threeD_dict={\n",
    "        'Repo name': repo_names,\n",
    "        'User name': user_names,\n",
    "        'Star count':stars_set,\n",
    "        'URL': repo_URLS\n",
    "}\n",
    "threeD_df=pd.DataFrame(ThreeD_dict)\n",
    "threeD_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff3877",
   "metadata": {},
   "source": [
    "Now, we will write functions to combine what we have done above and get all the details at once for any given `topic` URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "859df6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "def get_page(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if 200 <= response.status_code <= 299:\n",
    "        page_contents = response.text\n",
    "        doc = BeautifulSoup(page_contents, 'html.parser')\n",
    "        return doc\n",
    "    else:\n",
    "        raise Exception(\"Unable to fetch the given page\")\n",
    "\n",
    "def parse_page(doc):\n",
    "    topic_titles = []\n",
    "    topic_descs = []\n",
    "    topic_urls = []\n",
    "    \n",
    "    title_tags = doc.find_all('p', class_=\"f3 lh-condensed mb-0 mt-1 Link--primary\")\n",
    "    for tag in title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "        \n",
    "    desc_tags = doc.find_all('p', class_=\"f5 color-fg-muted mb-0 mt-1\")\n",
    "    for tag in desc_tags:\n",
    "        topic_descs.append(tag.text.strip())\n",
    "        \n",
    "    link_tags = doc.find_all('a', class_=\"no-underline flex-1 d-flex flex-column\")\n",
    "    base_url = \"https://github.com\"\n",
    "    for tag in link_tags:\n",
    "        helper_tag=tag['href']\n",
    "        topic_urls.append(base_url + helper_tag)\n",
    "\n",
    "    topic_dict = {\n",
    "        'title': topic_titles,\n",
    "        'description': topic_descs,\n",
    "        'url': topic_urls\n",
    "    }\n",
    "    \n",
    "    topic_df = pd.DataFrame(topic_dict)\n",
    "    topic_df.to_csv('topics.csv', index=None)\n",
    "    \n",
    "    return topic_dict\n",
    "\n",
    "def get_repo_info(topic_url):\n",
    "    soup = get_page(topic_url)\n",
    "    \n",
    "    h3_tags = soup.find_all('h3', class_=\"f3 color-fg-muted text-normal lh-condensed\")\n",
    "    \n",
    "    usernames = [tag.find_all('a')[0].text.strip() for tag in h3_tags[:10]]\n",
    "    \n",
    "    star_tags = soup.find_all('span', {'id': \"repo-stars-counter-star\"})\n",
    "    stars_set = [int(float(tag.text[:-1]) * 1000) if tag.text[-1] == 'k' else int(tag.text) for tag in star_tags[:10]]\n",
    "    \n",
    "    repo_names = [tag.find_all('a')[1].text.strip() for tag in h3_tags[:10]]\n",
    "    \n",
    "    repo_URLS = [f\"https://github.com{tag.find_all('a')[0]['href']}\" for tag in h3_tags[:10]]\n",
    "\n",
    "    repo_dict = {\n",
    "        'repo name': repo_names,\n",
    "        'user name': usernames,\n",
    "        'stars count': stars_set,\n",
    "        'repo url': repo_URLS\n",
    "    }\n",
    "    \n",
    "    repo_df = pd.DataFrame(repo_dict)\n",
    "    repo_df.to_csv('repo.csv', index=None)\n",
    "    \n",
    "    return repo_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b26a5869",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=get_page(\"https://github.com/topics\") \n",
    "doc_topics=parse_page(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12836f17",
   "metadata": {},
   "source": [
    "Now, similarly we will call the function `get_repo_info` , for all the 30 topics of our list ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5a904932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_save_topic_info(main_url):\n",
    "    page_doc = get_page(main_url)\n",
    "    topics_data = parse_page(page_doc)\n",
    "    \n",
    "    for i in range(0, 30):\n",
    "        repo_df = get_repo_info(topics_data['url'][i])\n",
    "        csv_name = topics_data['title'][i]\n",
    "        repo_df.to_csv(f\"{csv_name}_repos.csv\", index=None)\n",
    "        print(f\"Repository information for '{csv_name}' is saved as {csv_name}_repos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_and_save_topic_info(\"https://github.com/topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1310eeed",
   "metadata": {},
   "source": [
    "###### Let us look at the steps that we took from start to finish :\n",
    "\n",
    "We downloaded the webpage using requests\n",
    "\n",
    "We parsed the HTML source code using BeautifulSoup library and extracted the desired infromation, i.e.\n",
    "\n",
    "The names of 'First 30 Topics'\n",
    "URLs of each of those topics\n",
    "We created a DataFrame using Pandas for Python Lists that we derived from the previous step\n",
    "\n",
    "We extracted detailed information for each topic among the list of Topics, such as :\n",
    "\n",
    "Repository name\n",
    "User name\n",
    "Number of stars\n",
    "Repo url\n",
    "\n",
    "We then created a Python Dictionary to save all these details\n",
    "\n",
    "We converted the python dictionary into Pandas DataFrames\n",
    "\n",
    "With one single DataFrame in hand, we then converted it into a single CSV file, which was the goal of our project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf67d4d",
   "metadata": {},
   "source": [
    "\n",
    "References\n",
    "[1] Python offical documentation. https://docs.python.org/3/\n",
    "\n",
    "[2] Requests library. https://pypi.org/project/requests/\n",
    "\n",
    "[3] Beautiful Soup documentation. https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "[4] Aakash N S, Introduction to Web Scraping, 2021. https://jovian.ai/aakashns/python-web-scraping-and-rest-api\n",
    "\n",
    "[5] Pandas library documentation. https://pandas.pydata.org/docs/\n",
    "\n",
    "[6] Github Website: https://github.com/topics\n",
    "\n",
    "[7] Working with Jupyter Notebook https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "785f0df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in C:/Users/91790/scrapping-github-topics-repositories/.git/\n"
     ]
    }
   ],
   "source": [
    "!git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cf4393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t.ipynb_checkpoints/\n",
      "\t.jovianrc\n",
      "\t3D_repos.csv\n",
      "\tAPI_repos.csv\n",
      "\tASP.NET_repos.csv\n",
      "\tAjax_repos.csv\n",
      "\tAlgorithm_repos.csv\n",
      "\tAmazon Web Services_repos.csv\n",
      "\tAmp_repos.csv\n",
      "\tAndroid_repos.csv\n",
      "\tAngular_repos.csv\n",
      "\tAnsible_repos.csv\n",
      "\tArduino_repos.csv\n",
      "\tAtom_repos.csv\n",
      "\tAwesome Lists_repos.csv\n",
      "\tAzure_repos.csv\n",
      "\tBabel_repos.csv\n",
      "\tBash_repos.csv\n",
      "\tBitcoin_repos.csv\n",
      "\tBootstrap_repos.csv\n",
      "\tBot_repos.csv\n",
      "\tC++_repos.csv\n",
      "\tCOVID-19_repos.csv\n",
      "\tC_repos.csv\n",
      "\tChrome extension_repos.csv\n",
      "\tChrome_repos.csv\n",
      "\tClojure_repos.csv\n",
      "\tCode quality_repos.csv\n",
      "\tCode review_repos.csv\n",
      "\tCommand line interface_repos.csv\n",
      "\tCompiler_repos.csv\n",
      "\tContinuous integration_repos.csv\n",
      "\tUntitled.ipynb\n",
      "\tUntitled1.ipynb\n",
      "\tmaxresdefault.jpg\n",
      "\trepo.csv\n",
      "\tscrappin-github-topics-repositories.ipynb\n",
      "\ttopics.csv\n",
      "\twebpage.html\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b61768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of '.ipynb_checkpoints/Untitled-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of '.ipynb_checkpoints/Untitled1-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of '.ipynb_checkpoints/scrappin-github-topics-repositories-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Untitled.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Untitled1.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'scrappin-github-topics-repositories.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50c62935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: pathspec 'scrapping-github-topics-repositories' did not match any files\n"
     ]
    }
   ],
   "source": [
    "!git add scrapping-github-topics-repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "917d2f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7db6a23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dir>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d73ecb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is FE21-282C\n",
      "\n",
      " Directory of C:\\Users\\91790\\scrapping-github-topics-repositories\n",
      "\n",
      "21-01-2024  10:38    <DIR>          .\n",
      "21-01-2024  10:30    <DIR>          ..\n",
      "21-01-2024  10:38    <DIR>          .ipynb_checkpoints\n",
      "16-01-2024  18:09                23 .jovianrc\n",
      "20-01-2024  02:33               578 3D_repos.csv\n",
      "20-01-2024  02:33               595 Ajax_repos.csv\n",
      "20-01-2024  02:33               676 Algorithm_repos.csv\n",
      "20-01-2024  02:34               622 Amazon Web Services_repos.csv\n",
      "20-01-2024  02:33               539 Amp_repos.csv\n",
      "20-01-2024  02:33               649 Android_repos.csv\n",
      "20-01-2024  02:34               633 Angular_repos.csv\n",
      "20-01-2024  02:34               651 Ansible_repos.csv\n",
      "20-01-2024  02:34               540 API_repos.csv\n",
      "20-01-2024  02:34               637 Arduino_repos.csv\n",
      "20-01-2024  02:34               656 ASP.NET_repos.csv\n",
      "20-01-2024  02:34               556 Atom_repos.csv\n",
      "20-01-2024  02:34               716 Awesome Lists_repos.csv\n",
      "20-01-2024  02:34               644 Azure_repos.csv\n",
      "20-01-2024  02:34               640 Babel_repos.csv\n",
      "20-01-2024  02:34               596 Bash_repos.csv\n",
      "20-01-2024  02:34               557 Bitcoin_repos.csv\n",
      "20-01-2024  02:34               637 Bootstrap_repos.csv\n",
      "20-01-2024  02:34               576 Bot_repos.csv\n",
      "20-01-2024  02:34               653 C++_repos.csv\n",
      "20-01-2024  02:34               676 Chrome extension_repos.csv\n",
      "20-01-2024  02:34               632 Chrome_repos.csv\n",
      "20-01-2024  02:34               611 Clojure_repos.csv\n",
      "20-01-2024  02:34               638 Code quality_repos.csv\n",
      "20-01-2024  02:34               587 Code review_repos.csv\n",
      "20-01-2024  02:34               561 Command line interface_repos.csv\n",
      "20-01-2024  02:34               549 Compiler_repos.csv\n",
      "20-01-2024  02:34               569 Continuous integration_repos.csv\n",
      "20-01-2024  02:34               637 COVID-19_repos.csv\n",
      "20-01-2024  02:34               549 C_repos.csv\n",
      "20-01-2024  02:08            58,722 maxresdefault.jpg\n",
      "20-01-2024  02:34               653 repo.csv\n",
      "21-01-2024  10:36            43,141 scrapping-github-topics-repositories.ipynb\n",
      "20-01-2024  02:33             3,588 topics.csv\n",
      "20-01-2024  02:05            60,509 Untitled.ipynb\n",
      "19-01-2024  19:03            10,357 Untitled1.ipynb\n",
      "19-01-2024  20:25           173,227 webpage.html\n",
      "              38 File(s)        368,580 bytes\n",
      "               3 Dir(s)  30,334,554,112 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ae1b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is FE21-282C\n",
      "\n",
      " Directory of C:\\Users\\91790\\scrapping-github-topics-repositories\n",
      "\n",
      "21-01-2024  10:46    <DIR>          .\n",
      "21-01-2024  10:46    <DIR>          ..\n",
      "21-01-2024  10:46    <DIR>          .ipynb_checkpoints\n",
      "16-01-2024  18:09                23 .jovianrc\n",
      "21-01-2024  10:43            50,558 scrapping-github-topics-repositories.ipynb\n",
      "               2 File(s)         50,581 bytes\n",
      "               3 Dir(s)  30,358,142,976 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "276845a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in C:/Users/91790/scrapping-github-topics-repositories/.git/\n"
     ]
    }
   ],
   "source": [
    "!git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5ca675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is FE21-282C\n",
      "\n",
      " Directory of C:\\Users\\91790\\scrapping-github-topics-repositories\n",
      "\n",
      "21-01-2024  10:47    <DIR>          .\n",
      "21-01-2024  10:46    <DIR>          ..\n",
      "21-01-2024  10:46    <DIR>          .ipynb_checkpoints\n",
      "16-01-2024  18:09                23 .jovianrc\n",
      "21-01-2024  10:47            51,794 scrapping-github-topics-repositories.ipynb\n",
      "               2 File(s)         51,817 bytes\n",
      "               3 Dir(s)  30,362,083,328 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84e8d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f210f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is FE21-282C\n",
      "\n",
      " Directory of C:\\Users\\91790\\scrapping-github-topics-repositories\n",
      "\n",
      "21-01-2024  10:47    <DIR>          .\n",
      "21-01-2024  10:46    <DIR>          ..\n",
      "21-01-2024  10:46    <DIR>          .ipynb_checkpoints\n",
      "16-01-2024  18:09                23 .jovianrc\n",
      "21-01-2024  10:47            51,794 scrapping-github-topics-repositories.ipynb\n",
      "               2 File(s)         51,817 bytes\n",
      "               3 Dir(s)  30,361,972,736 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6c69367",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd C:\\Users\\91790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1d7b1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is FE21-282C\n",
      "\n",
      " Directory of C:\\Users\\91790\\scrapping-github-topics-repositories\n",
      "\n",
      "21-01-2024  10:49    <DIR>          .\n",
      "21-01-2024  10:46    <DIR>          ..\n",
      "21-01-2024  10:46    <DIR>          .ipynb_checkpoints\n",
      "16-01-2024  18:09                23 .jovianrc\n",
      "21-01-2024  10:49            53,314 scrapping-github-topics-repositories.ipynb\n",
      "               2 File(s)         53,337 bytes\n",
      "               3 Dir(s)  30,361,645,056 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e2e62e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git rm --cached <file>...\" to unstage)\n",
      "\tnew file:   .ipynb_checkpoints/Untitled-checkpoint.ipynb\n",
      "\tnew file:   .ipynb_checkpoints/Untitled1-checkpoint.ipynb\n",
      "\tnew file:   .ipynb_checkpoints/scrappin-github-topics-repositories-checkpoint.ipynb\n",
      "\tnew file:   .jovianrc\n",
      "\tnew file:   3D_repos.csv\n",
      "\tnew file:   API_repos.csv\n",
      "\tnew file:   ASP.NET_repos.csv\n",
      "\tnew file:   Ajax_repos.csv\n",
      "\tnew file:   Algorithm_repos.csv\n",
      "\tnew file:   Amazon Web Services_repos.csv\n",
      "\tnew file:   Amp_repos.csv\n",
      "\tnew file:   Android_repos.csv\n",
      "\tnew file:   Angular_repos.csv\n",
      "\tnew file:   Ansible_repos.csv\n",
      "\tnew file:   Arduino_repos.csv\n",
      "\tnew file:   Atom_repos.csv\n",
      "\tnew file:   Awesome Lists_repos.csv\n",
      "\tnew file:   Azure_repos.csv\n",
      "\tnew file:   Babel_repos.csv\n",
      "\tnew file:   Bash_repos.csv\n",
      "\tnew file:   Bitcoin_repos.csv\n",
      "\tnew file:   Bootstrap_repos.csv\n",
      "\tnew file:   Bot_repos.csv\n",
      "\tnew file:   C++_repos.csv\n",
      "\tnew file:   COVID-19_repos.csv\n",
      "\tnew file:   C_repos.csv\n",
      "\tnew file:   Chrome extension_repos.csv\n",
      "\tnew file:   Chrome_repos.csv\n",
      "\tnew file:   Clojure_repos.csv\n",
      "\tnew file:   Code quality_repos.csv\n",
      "\tnew file:   Code review_repos.csv\n",
      "\tnew file:   Command line interface_repos.csv\n",
      "\tnew file:   Compiler_repos.csv\n",
      "\tnew file:   Continuous integration_repos.csv\n",
      "\tnew file:   Untitled.ipynb\n",
      "\tnew file:   Untitled1.ipynb\n",
      "\tnew file:   maxresdefault.jpg\n",
      "\tnew file:   repo.csv\n",
      "\tnew file:   scrappin-github-topics-repositories.ipynb\n",
      "\tnew file:   topics.csv\n",
      "\tnew file:   webpage.html\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add/rm <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tdeleted:    .ipynb_checkpoints/Untitled-checkpoint.ipynb\n",
      "\tdeleted:    .ipynb_checkpoints/Untitled1-checkpoint.ipynb\n",
      "\tdeleted:    .ipynb_checkpoints/scrappin-github-topics-repositories-checkpoint.ipynb\n",
      "\tdeleted:    3D_repos.csv\n",
      "\tdeleted:    API_repos.csv\n",
      "\tdeleted:    ASP.NET_repos.csv\n",
      "\tdeleted:    Ajax_repos.csv\n",
      "\tdeleted:    Algorithm_repos.csv\n",
      "\tdeleted:    Amazon Web Services_repos.csv\n",
      "\tdeleted:    Amp_repos.csv\n",
      "\tdeleted:    Android_repos.csv\n",
      "\tdeleted:    Angular_repos.csv\n",
      "\tdeleted:    Ansible_repos.csv\n",
      "\tdeleted:    Arduino_repos.csv\n",
      "\tdeleted:    Atom_repos.csv\n",
      "\tdeleted:    Awesome Lists_repos.csv\n",
      "\tdeleted:    Azure_repos.csv\n",
      "\tdeleted:    Babel_repos.csv\n",
      "\tdeleted:    Bash_repos.csv\n",
      "\tdeleted:    Bitcoin_repos.csv\n",
      "\tdeleted:    Bootstrap_repos.csv\n",
      "\tdeleted:    Bot_repos.csv\n",
      "\tdeleted:    C++_repos.csv\n",
      "\tdeleted:    COVID-19_repos.csv\n",
      "\tdeleted:    C_repos.csv\n",
      "\tdeleted:    Chrome extension_repos.csv\n",
      "\tdeleted:    Chrome_repos.csv\n",
      "\tdeleted:    Clojure_repos.csv\n",
      "\tdeleted:    Code quality_repos.csv\n",
      "\tdeleted:    Code review_repos.csv\n",
      "\tdeleted:    Command line interface_repos.csv\n",
      "\tdeleted:    Compiler_repos.csv\n",
      "\tdeleted:    Continuous integration_repos.csv\n",
      "\tdeleted:    Untitled.ipynb\n",
      "\tdeleted:    Untitled1.ipynb\n",
      "\tdeleted:    maxresdefault.jpg\n",
      "\tdeleted:    repo.csv\n",
      "\tdeleted:    scrappin-github-topics-repositories.ipynb\n",
      "\tdeleted:    topics.csv\n",
      "\tdeleted:    webpage.html\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t.ipynb_checkpoints/scrapping-github-topics-repositories-checkpoint.ipynb\n",
      "\tscrapping-github-topics-repositories.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "083e7303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: pathspec 'scrapping-github-topics-repositories' did not match any files\n"
     ]
    }
   ],
   "source": [
    "!git add scrapping-github-topics-repositories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf7588f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
